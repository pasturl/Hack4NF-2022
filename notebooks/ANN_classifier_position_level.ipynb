{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import synapseclient\n",
    "import synapseutils\n",
    " \n",
    "syn = synapseclient.Synapse()\n",
    "syn.login(None, None, None, None, True, True, False, 'eyJ0eXAiOiJKV1QiLCJraWQiOiJXN05OOldMSlQ6SjVSSzpMN1RMOlQ3TDc6M1ZYNjpKRU9VOjY0NFI6VTNJWDo1S1oyOjdaQ0s6RlBUSCIsImFsZyI6IlJTMjU2In0.eyJhY2Nlc3MiOnsic2NvcGUiOlsidmlldyIsImRvd25sb2FkIl0sIm9pZGNfY2xhaW1zIjp7fX0sInRva2VuX3R5cGUiOiJQRVJTT05BTF9BQ0NFU1NfVE9LRU4iLCJpc3MiOiJodHRwczovL3JlcG8tcHJvZC00MjgtMC5wcm9kLnNhZ2ViYXNlLm9yZy9hdXRoL3YxIiwiYXVkIjoiMCIsIm5iZiI6MTY2NzMxNjU5NywiaWF0IjoxNjY3MzE2NTk3LCJqdGkiOiIyMjA2Iiwic3ViIjoiMzQ1ODEyMCJ9.fDT3ayb3svthkWQensecPnwXTMk-byieyDbZlYaRn_zryTJQ4_1n0y_SVJ1IpQ6kkrXzqGt0cQu2hSWyXOJ87_A6GsAjCfH5apiItzx3imYPAWwzsD_1W-MyjdETTcJqDpAgAUF18W9NUZ19lTDSBkvBuvfSTkbJ2EXVtkdO2PI3cqBNLDlZVS2BbN_HAp1x6wTtww5Zs3uegOZmSfR9N7JmYDTkaZyF7JbT6Mz_traBR84cKrKQ8xDR-Muf9FnXrP45vHPgw3VOiXThr0uAr1YJtZTqyT2yTkJPvCC8kyy6_3QrQNooeAM7IP_VtENB7kbD97qjL2FY_EwmGnKFAg')\n",
    "files = synapseutils.syncFromSynapse(syn, 'syn36709873', path='./genie-v13.3-data', ifcollision='overwrite.local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = dict()\n",
    "cancer_types = []\n",
    "cancer_types_detailed = []\n",
    "features = {\n",
    "  # 'start_position': { 'options': [] },\n",
    "  # 'end_position': { 'options': [] },\n",
    "  # 'consequence': { 'options': [] },\n",
    "  'variant_classification': { 'options': [] },\n",
    "  'variant_type': { 'options': [] },\n",
    "  # 'reference_allele': { 'options': [] },\n",
    "  # 'tumor_seq_allele1': { 'options': [] },\n",
    "  # 'tumor_seq_allele2': { 'options': [] },\n",
    "  'protein_position': { 'options': [] },\n",
    "  'protein_change': { 'options': [] },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# Genie samples\n",
    "\n",
    "with open('./genie-v13.3-data/data_mutations_extended_13.3-consortium.txt', 'r') as f:\n",
    "    fileReader = reader(f, delimiter='\\t')\n",
    "    header = next(fileReader)\n",
    "    hugo_symbol_index = header.index('Hugo_Symbol')\n",
    "    sample_id_index = header.index('Tumor_Sample_Barcode')\n",
    "    start_position_index = header.index('Start_Position')\n",
    "    end_position_index = header.index('End_Position')\n",
    "    consequence_index = header.index('Consequence')\n",
    "    variant_classification_index = header.index('Variant_Classification')\n",
    "    variant_type_index = header.index('Variant_Type')\n",
    "    reference_allele_index = header.index('Reference_Allele')\n",
    "    tumor_seq_allele1_index = header.index('Tumor_Seq_Allele1')\n",
    "    tumor_seq_allele2_index = header.index('Tumor_Seq_Allele2')\n",
    "    protein_position_index = header.index('Protein_position')\n",
    "    protein_change_index = header.index('HGVSp_Short')\n",
    "    if(hugo_symbol_index == -1):\n",
    "        raise Exception('Hugo_Symbol column not found')\n",
    "    for row in fileReader:\n",
    "        if row[hugo_symbol_index] == 'NF1':\n",
    "            sample = {\n",
    "                'sample_id': row[sample_id_index],\n",
    "                'start_position': row[start_position_index],\n",
    "                'end_position': row[end_position_index],\n",
    "                'consequence': row[consequence_index],\n",
    "                'variant_classification': row[variant_classification_index],\n",
    "                'variant_type': row[variant_type_index],\n",
    "                'reference_allele': row[reference_allele_index],\n",
    "                'tumor_seq_allele1': row[tumor_seq_allele1_index],\n",
    "                'tumor_seq_allele2': row[tumor_seq_allele2_index],\n",
    "                'protein_position': row[protein_position_index],\n",
    "                'protein_change': row[protein_change_index]\n",
    "            }\n",
    "            if sample['reference_allele'].__len__() == 1 and sample['tumor_seq_allele1'].__len__() == 1 and sample['tumor_seq_allele2'].__len__() == 1:\n",
    "                for feature in features:\n",
    "                    if sample[feature] not in features[feature]['options']:\n",
    "                        features[feature]['options'].append(sample[feature])\n",
    "                samples[sample['sample_id']] = sample\n",
    "with open('./genie-v13.3-data/data_clinical_sample_13.3-consortium.txt', 'r') as f:\n",
    "    fileReader = reader(f, delimiter='\\t')\n",
    "    ignore = next(fileReader)\n",
    "    ignore = next(fileReader)\n",
    "    ignore = next(fileReader)\n",
    "    ignore = next(fileReader)\n",
    "    header = next(fileReader)\n",
    "    sample_id_index = header.index('SAMPLE_ID')\n",
    "    cancer_type_index = header.index('CANCER_TYPE')\n",
    "    cancer_type_detailed_index = header.index('CANCER_TYPE_DETAILED')\n",
    "    for row in fileReader:\n",
    "        sample_id = row[sample_id_index]    \n",
    "        if sample_id in samples:\n",
    "            if row[cancer_type_index] not in cancer_types:\n",
    "                cancer_types.append(row[cancer_type_index])\n",
    "            if row[cancer_type_detailed_index] not in cancer_types_detailed:\n",
    "                cancer_types_detailed.append(row[cancer_type_detailed_index])\n",
    "            sample = samples[sample_id]\n",
    "            sample['cancer_type'] = row[cancer_type_index]\n",
    "            sample['cancer_type_detailed'] = row[cancer_type_detailed_index]\n",
    "            samples[sample_id] = sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 7017\n",
      "test samples: 7017\n",
      "torch.Size([64, 6316])\n",
      "torch.Size([64, 445])\n",
      "mps\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.693935  [    0/ 7017]\n",
      "loss: 0.024094  [ 3200/ 7017]\n",
      "loss: 0.021230  [ 6400/ 7017]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.021372  [    0/ 7017]\n",
      "loss: 0.019125  [ 3200/ 7017]\n",
      "loss: 0.021387  [ 6400/ 7017]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.020127  [    0/ 7017]\n",
      "loss: 0.019437  [ 3200/ 7017]\n",
      "loss: 0.020621  [ 6400/ 7017]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.021300  [    0/ 7017]\n",
      "loss: 0.019700  [ 3200/ 7017]\n",
      "loss: 0.020374  [ 6400/ 7017]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.019865  [    0/ 7017]\n",
      "loss: 0.020877  [ 3200/ 7017]\n",
      "loss: 0.019061  [ 6400/ 7017]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.019261  [    0/ 7017]\n",
      "loss: 0.017997  [ 3200/ 7017]\n",
      "loss: 0.017872  [ 6400/ 7017]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.017799  [    0/ 7017]\n",
      "loss: 0.015606  [ 3200/ 7017]\n",
      "loss: 0.017530  [ 6400/ 7017]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.019297  [    0/ 7017]\n",
      "loss: 0.015396  [ 3200/ 7017]\n",
      "loss: 0.015458  [ 6400/ 7017]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.016650  [    0/ 7017]\n",
      "loss: 0.014594  [ 3200/ 7017]\n",
      "loss: 0.015147  [ 6400/ 7017]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.011866  [    0/ 7017]\n",
      "loss: 0.013722  [ 3200/ 7017]\n",
      "loss: 0.014393  [ 6400/ 7017]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.012417  [    0/ 7017]\n",
      "loss: 0.014268  [ 3200/ 7017]\n",
      "loss: 0.013879  [ 6400/ 7017]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.011763  [    0/ 7017]\n",
      "loss: 0.014867  [ 3200/ 7017]\n",
      "loss: 0.011983  [ 6400/ 7017]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.011131  [    0/ 7017]\n",
      "loss: 0.013397  [ 3200/ 7017]\n",
      "loss: 0.014120  [ 6400/ 7017]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.011652  [    0/ 7017]\n",
      "loss: 0.011810  [ 3200/ 7017]\n",
      "loss: 0.012341  [ 6400/ 7017]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.011830  [    0/ 7017]\n",
      "loss: 0.009448  [ 3200/ 7017]\n",
      "loss: 0.011095  [ 6400/ 7017]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.007179  [    0/ 7017]\n",
      "loss: 0.010836  [ 3200/ 7017]\n",
      "loss: 0.009196  [ 6400/ 7017]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.009497  [    0/ 7017]\n",
      "loss: 0.010522  [ 3200/ 7017]\n",
      "loss: 0.010787  [ 6400/ 7017]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.008523  [    0/ 7017]\n",
      "loss: 0.010431  [ 3200/ 7017]\n",
      "loss: 0.010804  [ 6400/ 7017]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.007167  [    0/ 7017]\n",
      "loss: 0.010046  [ 3200/ 7017]\n",
      "loss: 0.010015  [ 6400/ 7017]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.009293  [    0/ 7017]\n",
      "loss: 0.008718  [ 3200/ 7017]\n",
      "loss: 0.010739  [ 6400/ 7017]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.009290  [    0/ 7017]\n",
      "loss: 0.010840  [ 3200/ 7017]\n",
      "loss: 0.009613  [ 6400/ 7017]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.007157  [    0/ 7017]\n",
      "loss: 0.009734  [ 3200/ 7017]\n",
      "loss: 0.011327  [ 6400/ 7017]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.008916  [    0/ 7017]\n",
      "loss: 0.008387  [ 3200/ 7017]\n",
      "loss: 0.010142  [ 6400/ 7017]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.008133  [    0/ 7017]\n",
      "loss: 0.007253  [ 3200/ 7017]\n",
      "loss: 0.007742  [ 6400/ 7017]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.007474  [    0/ 7017]\n",
      "loss: 0.008957  [ 3200/ 7017]\n",
      "loss: 0.008801  [ 6400/ 7017]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.007735  [    0/ 7017]\n",
      "loss: 0.007624  [ 3200/ 7017]\n",
      "loss: 0.009336  [ 6400/ 7017]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.008095  [    0/ 7017]\n",
      "loss: 0.007771  [ 3200/ 7017]\n",
      "loss: 0.006065  [ 6400/ 7017]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.008171  [    0/ 7017]\n",
      "loss: 0.007316  [ 3200/ 7017]\n",
      "loss: 0.008786  [ 6400/ 7017]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.008395  [    0/ 7017]\n",
      "loss: 0.008642  [ 3200/ 7017]\n",
      "loss: 0.009253  [ 6400/ 7017]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.008097  [    0/ 7017]\n",
      "loss: 0.007118  [ 3200/ 7017]\n",
      "loss: 0.008289  [ 6400/ 7017]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.007543  [    0/ 7017]\n",
      "loss: 0.007589  [ 3200/ 7017]\n",
      "loss: 0.007017  [ 6400/ 7017]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.006912  [    0/ 7017]\n",
      "loss: 0.007486  [ 3200/ 7017]\n",
      "loss: 0.009577  [ 6400/ 7017]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.007629  [    0/ 7017]\n",
      "loss: 0.008698  [ 3200/ 7017]\n",
      "loss: 0.007862  [ 6400/ 7017]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.006671  [    0/ 7017]\n",
      "loss: 0.006507  [ 3200/ 7017]\n",
      "loss: 0.008193  [ 6400/ 7017]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.007599  [    0/ 7017]\n",
      "loss: 0.006830  [ 3200/ 7017]\n",
      "loss: 0.006993  [ 6400/ 7017]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.005769  [    0/ 7017]\n",
      "loss: 0.006682  [ 3200/ 7017]\n",
      "loss: 0.009217  [ 6400/ 7017]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.007039  [    0/ 7017]\n",
      "loss: 0.005961  [ 3200/ 7017]\n",
      "loss: 0.007306  [ 6400/ 7017]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.007440  [    0/ 7017]\n",
      "loss: 0.007338  [ 3200/ 7017]\n",
      "loss: 0.008804  [ 6400/ 7017]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.008752  [    0/ 7017]\n",
      "loss: 0.008219  [ 3200/ 7017]\n",
      "loss: 0.007735  [ 6400/ 7017]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.005956  [    0/ 7017]\n",
      "loss: 0.007823  [ 3200/ 7017]\n",
      "loss: 0.007058  [ 6400/ 7017]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.007011  [    0/ 7017]\n",
      "loss: 0.008756  [ 3200/ 7017]\n",
      "loss: 0.007913  [ 6400/ 7017]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.006632  [    0/ 7017]\n",
      "loss: 0.007711  [ 3200/ 7017]\n",
      "loss: 0.007640  [ 6400/ 7017]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.006561  [    0/ 7017]\n",
      "loss: 0.007001  [ 3200/ 7017]\n",
      "loss: 0.010766  [ 6400/ 7017]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.007861  [    0/ 7017]\n",
      "loss: 0.006699  [ 3200/ 7017]\n",
      "loss: 0.008790  [ 6400/ 7017]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.006686  [    0/ 7017]\n",
      "loss: 0.006424  [ 3200/ 7017]\n",
      "loss: 0.006184  [ 6400/ 7017]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.007725  [    0/ 7017]\n",
      "loss: 0.005728  [ 3200/ 7017]\n",
      "loss: 0.008638  [ 6400/ 7017]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.005524  [    0/ 7017]\n",
      "loss: 0.006860  [ 3200/ 7017]\n",
      "loss: 0.008088  [ 6400/ 7017]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.006582  [    0/ 7017]\n",
      "loss: 0.006610  [ 3200/ 7017]\n",
      "loss: 0.008360  [ 6400/ 7017]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.006105  [    0/ 7017]\n",
      "loss: 0.005280  [ 3200/ 7017]\n",
      "loss: 0.008170  [ 6400/ 7017]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.006625  [    0/ 7017]\n",
      "loss: 0.007726  [ 3200/ 7017]\n",
      "loss: 0.007166  [ 6400/ 7017]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.006665  [    0/ 7017]\n",
      "loss: 0.007480  [ 3200/ 7017]\n",
      "loss: 0.007848  [ 6400/ 7017]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.006852  [    0/ 7017]\n",
      "loss: 0.007330  [ 3200/ 7017]\n",
      "loss: 0.008148  [ 6400/ 7017]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.006928  [    0/ 7017]\n",
      "loss: 0.008222  [ 3200/ 7017]\n",
      "loss: 0.009271  [ 6400/ 7017]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.005440  [    0/ 7017]\n",
      "loss: 0.005652  [ 3200/ 7017]\n",
      "loss: 0.007035  [ 6400/ 7017]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.007279  [    0/ 7017]\n",
      "loss: 0.005534  [ 3200/ 7017]\n",
      "loss: 0.006784  [ 6400/ 7017]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.006905  [    0/ 7017]\n",
      "loss: 0.006526  [ 3200/ 7017]\n",
      "loss: 0.007903  [ 6400/ 7017]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.005918  [    0/ 7017]\n",
      "loss: 0.006904  [ 3200/ 7017]\n",
      "loss: 0.007019  [ 6400/ 7017]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.006482  [    0/ 7017]\n",
      "loss: 0.007493  [ 3200/ 7017]\n",
      "loss: 0.006518  [ 6400/ 7017]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.006844  [    0/ 7017]\n",
      "loss: 0.007346  [ 3200/ 7017]\n",
      "loss: 0.006916  [ 6400/ 7017]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.005685  [    0/ 7017]\n",
      "loss: 0.008379  [ 3200/ 7017]\n",
      "loss: 0.006581  [ 6400/ 7017]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.007180  [    0/ 7017]\n",
      "loss: 0.007097  [ 3200/ 7017]\n",
      "loss: 0.009230  [ 6400/ 7017]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.007364  [    0/ 7017]\n",
      "loss: 0.006734  [ 3200/ 7017]\n",
      "loss: 0.008739  [ 6400/ 7017]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.005765  [    0/ 7017]\n",
      "loss: 0.007836  [ 3200/ 7017]\n",
      "loss: 0.008841  [ 6400/ 7017]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.007426  [    0/ 7017]\n",
      "loss: 0.006721  [ 3200/ 7017]\n",
      "loss: 0.007557  [ 6400/ 7017]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.006807  [    0/ 7017]\n",
      "loss: 0.007970  [ 3200/ 7017]\n",
      "loss: 0.006709  [ 6400/ 7017]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.007623  [    0/ 7017]\n",
      "loss: 0.006122  [ 3200/ 7017]\n",
      "loss: 0.007964  [ 6400/ 7017]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.006841  [    0/ 7017]\n",
      "loss: 0.007675  [ 3200/ 7017]\n",
      "loss: 0.005290  [ 6400/ 7017]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.007611  [    0/ 7017]\n",
      "loss: 0.007877  [ 3200/ 7017]\n",
      "loss: 0.007116  [ 6400/ 7017]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.006124  [    0/ 7017]\n",
      "loss: 0.007047  [ 3200/ 7017]\n",
      "loss: 0.007427  [ 6400/ 7017]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.007557  [    0/ 7017]\n",
      "loss: 0.007108  [ 3200/ 7017]\n",
      "loss: 0.006251  [ 6400/ 7017]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.005612  [    0/ 7017]\n",
      "loss: 0.007161  [ 3200/ 7017]\n",
      "loss: 0.006981  [ 6400/ 7017]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.007557  [    0/ 7017]\n",
      "loss: 0.007818  [ 3200/ 7017]\n",
      "loss: 0.007227  [ 6400/ 7017]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.005524  [    0/ 7017]\n",
      "loss: 0.006228  [ 3200/ 7017]\n",
      "loss: 0.007796  [ 6400/ 7017]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.005253  [    0/ 7017]\n",
      "loss: 0.007041  [ 3200/ 7017]\n",
      "loss: 0.006284  [ 6400/ 7017]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.007744  [    0/ 7017]\n",
      "loss: 0.006248  [ 3200/ 7017]\n",
      "loss: 0.007238  [ 6400/ 7017]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.006757  [    0/ 7017]\n",
      "loss: 0.006492  [ 3200/ 7017]\n",
      "loss: 0.007678  [ 6400/ 7017]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.006231  [    0/ 7017]\n",
      "loss: 0.005803  [ 3200/ 7017]\n",
      "loss: 0.008704  [ 6400/ 7017]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.007654  [    0/ 7017]\n",
      "loss: 0.006956  [ 3200/ 7017]\n",
      "loss: 0.008938  [ 6400/ 7017]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.007110  [    0/ 7017]\n",
      "loss: 0.007559  [ 3200/ 7017]\n",
      "loss: 0.008024  [ 6400/ 7017]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.006951  [    0/ 7017]\n",
      "loss: 0.006815  [ 3200/ 7017]\n",
      "loss: 0.008148  [ 6400/ 7017]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.006925  [    0/ 7017]\n",
      "loss: 0.006968  [ 3200/ 7017]\n",
      "loss: 0.006798  [ 6400/ 7017]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.006400  [    0/ 7017]\n",
      "loss: 0.006410  [ 3200/ 7017]\n",
      "loss: 0.006800  [ 6400/ 7017]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.005590  [    0/ 7017]\n",
      "loss: 0.008351  [ 3200/ 7017]\n",
      "loss: 0.009043  [ 6400/ 7017]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.006290  [    0/ 7017]\n",
      "loss: 0.006478  [ 3200/ 7017]\n",
      "loss: 0.007450  [ 6400/ 7017]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.006249  [    0/ 7017]\n",
      "loss: 0.007406  [ 3200/ 7017]\n",
      "loss: 0.006840  [ 6400/ 7017]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.007716  [    0/ 7017]\n",
      "loss: 0.008620  [ 3200/ 7017]\n",
      "loss: 0.007328  [ 6400/ 7017]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.005416  [    0/ 7017]\n",
      "loss: 0.007301  [ 3200/ 7017]\n",
      "loss: 0.006251  [ 6400/ 7017]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.006143  [    0/ 7017]\n",
      "loss: 0.007620  [ 3200/ 7017]\n",
      "loss: 0.006669  [ 6400/ 7017]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.007499  [    0/ 7017]\n",
      "loss: 0.007932  [ 3200/ 7017]\n",
      "loss: 0.007125  [ 6400/ 7017]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.008122  [    0/ 7017]\n",
      "loss: 0.007504  [ 3200/ 7017]\n",
      "loss: 0.007531  [ 6400/ 7017]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.007041  [    0/ 7017]\n",
      "loss: 0.007245  [ 3200/ 7017]\n",
      "loss: 0.007289  [ 6400/ 7017]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.006087  [    0/ 7017]\n",
      "loss: 0.007815  [ 3200/ 7017]\n",
      "loss: 0.008346  [ 6400/ 7017]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.005370  [    0/ 7017]\n",
      "loss: 0.006287  [ 3200/ 7017]\n",
      "loss: 0.006524  [ 6400/ 7017]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.006139  [    0/ 7017]\n",
      "loss: 0.004930  [ 3200/ 7017]\n",
      "loss: 0.007826  [ 6400/ 7017]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.006647  [    0/ 7017]\n",
      "loss: 0.007748  [ 3200/ 7017]\n",
      "loss: 0.007761  [ 6400/ 7017]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.006731  [    0/ 7017]\n",
      "loss: 0.006712  [ 3200/ 7017]\n",
      "loss: 0.007518  [ 6400/ 7017]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.005210  [    0/ 7017]\n",
      "loss: 0.007069  [ 3200/ 7017]\n",
      "loss: 0.006832  [ 6400/ 7017]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.005536  [    0/ 7017]\n",
      "loss: 0.007291  [ 3200/ 7017]\n",
      "loss: 0.006307  [ 6400/ 7017]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.006709  [    0/ 7017]\n",
      "loss: 0.005200  [ 3200/ 7017]\n",
      "loss: 0.007418  [ 6400/ 7017]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.006226  [    0/ 7017]\n",
      "loss: 0.006743  [ 3200/ 7017]\n",
      "loss: 0.007301  [ 6400/ 7017]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# shape = (len(cancer_types), len(cancer_types_detailed))\n",
    "# for sample in samples.values():\n",
    "#     matrix = np.zeros(shape)\n",
    "#     matrix[cancer_types.index(sample['cancer_type']), cancer_types_detailed.index(sample['cancer_type_detailed'])] += 1\n",
    "#     sample['matrix'] = matrix\n",
    "#     samples[sample['sample_id']] = sample\n",
    "\n",
    "# print(samples['GENIE-MSK-P-0015081-T03-IM7']['matrix'])\n",
    "tensor_size = 0\n",
    "for feature in features:\n",
    "    tensor_size += len(features[feature]['options'])\n",
    "\n",
    "target_tensor_size = len(cancer_types) + len(cancer_types_detailed)\n",
    "# print(features)\n",
    "\n",
    "class NF1DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index]\n",
    "        tensor = torch.zeros(tensor_size)\n",
    "        start_position = 0\n",
    "        for feature in features:\n",
    "            tensor[start_position + features[feature]['options'].index(sample[feature])] += 1\n",
    "            start_position += len(features[feature]['options'])\n",
    "        target_tensor = torch.zeros(target_tensor_size)\n",
    "        target_tensor[cancer_types.index(sample['cancer_type'])] += 1\n",
    "        target_tensor[len(cancer_types) + cancer_types_detailed.index(sample['cancer_type_detailed'])] += 1\n",
    "        return tensor, target_tensor\n",
    "\n",
    "training_samples = list(samples.values())\n",
    "test_samples = list(samples.values())\n",
    "print(f\"training samples: {len(training_samples)}\")\n",
    "print(f\"test samples: {len(test_samples)}\")\n",
    "training_data = NF1DataSet(training_samples)\n",
    "training_data_loader = torch.utils.data.DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_data = NF1DataSet(test_samples)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "for X, y in training_data_loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "class NF1Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NF1Model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(tensor_size, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 512)\n",
    "        self.fc3 = torch.nn.Linear(512, target_tensor_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = NF1Model().to(device)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Avg loss: {test_loss:>8f}, Accuracy: {correct:>5f}\")\n",
    "\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(training_data_loader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.006321, Accuracy: 0.459313\n"
     ]
    }
   ],
   "source": [
    "test_samples = list(samples.values())\n",
    "test_data = NF1DataSet(test_samples)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "test(test_data_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [133], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m sample \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m   \u001b[39m'\u001b[39m\u001b[39msample_id\u001b[39m\u001b[39m'\u001b[39m: row[sample_id_index],\n\u001b[1;32m      3\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mstart_position\u001b[39m\u001b[39m'\u001b[39m: row[start_position_index],\n\u001b[1;32m      4\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mend_position\u001b[39m\u001b[39m'\u001b[39m: row[end_position_index],\n\u001b[1;32m      5\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mconsequence\u001b[39m\u001b[39m'\u001b[39m: row[consequence_index],\n\u001b[1;32m      6\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mvariant_classification\u001b[39m\u001b[39m'\u001b[39m: row[variant_classification_index],\n\u001b[1;32m      7\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mvariant_type\u001b[39m\u001b[39m'\u001b[39m: row[variant_type_index],\n\u001b[1;32m      8\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mreference_allele\u001b[39m\u001b[39m'\u001b[39m: row[reference_allele_index],\n\u001b[0;32m----> 9\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mtumor_seq_allele1\u001b[39m\u001b[39m'\u001b[39m: row[tumor_seq_allele1_index],\n\u001b[1;32m     10\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mtumor_seq_allele2\u001b[39m\u001b[39m'\u001b[39m: row[tumor_seq_allele2_index],\n\u001b[1;32m     11\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mprotein_position\u001b[39m\u001b[39m'\u001b[39m: row[protein_position_index],\n\u001b[1;32m     12\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mprotein_change\u001b[39m\u001b[39m'\u001b[39m: row[protein_change_index]\n\u001b[1;32m     13\u001b[0m }\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "  'sample_id': row[sample_id_index],\n",
    "  'start_position': row[start_position_index],\n",
    "  'end_position': row[end_position_index],\n",
    "  'consequence': row[consequence_index],\n",
    "  'variant_classification': row[variant_classification_index],\n",
    "  'variant_type': row[variant_type_index],\n",
    "  'reference_allele': row[reference_allele_index],\n",
    "  'tumor_seq_allele1': row[tumor_seq_allele1_index],\n",
    "  'tumor_seq_allele2': row[tumor_seq_allele2_index],\n",
    "  'protein_position': row[protein_position_index],\n",
    "  'protein_change': row[protein_change_index]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
