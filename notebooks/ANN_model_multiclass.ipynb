{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6fdb9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataset import create_dataset\n",
    "from ml_model import train_model\n",
    "\n",
    "from utils import read_yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed946e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa9e555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Hack4NF:Reading config files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logging.basicConfig()\n",
    "logging.root.setLevel(logging.INFO)\n",
    "log = logging.getLogger('Hack4NF')\n",
    "\n",
    "\n",
    "log.info('Reading config files')\n",
    "# Read configuration files\n",
    "config_path = \"config/resources.yaml\"\n",
    "config = read_yaml(config_path)\n",
    "genie = config[\"genie\"]\n",
    "\n",
    "\n",
    "# Read synapses credentials\n",
    "secrets_path = \".secrets/synapses_credentials.yaml\"\n",
    "credentials = read_yaml(secrets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfeb000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Hack4NF:Creating dataset\n",
      "INFO:dataset:Reading dataset from: data//dataset.csv\n",
      "Columns (4,5,9,10,12) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "log.info('Creating dataset')\n",
    "dataset = create_dataset(genie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93a3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.dropna(subset=genie[\"targets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "789f88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/genie_mutations_features.txt') as f:\n",
    "    mutation_cols = f.read().splitlines()\n",
    "features = set(mutation_cols) - set(genie[\"targets\"])\n",
    "features = list(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9132f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ds[features].astype(int).values, ds[genie[\"targets\"]].astype(int).values,\n",
    "                                                    test_size=0.20, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "35621f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d3c9918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f7e54689",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.reshape(-1, X_train.shape[1]).astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "x_test = X_test.reshape(-1, X_test.shape[1]).astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a92c6639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105034, 5428)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "228f7d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26259, 5428)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c32aba3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26259, 10)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f339faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_val = torch.from_numpy(x_val)\n",
    "# y_val = torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a1c3e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/nicohrubec/pytorch-multilabel-neural-network/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b95b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.x=torch.from_numpy(X_data)\n",
    "        self.y=torch.from_numpy(y_data)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "469e6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=Data(x_train, y_train)\n",
    "test_set=Data(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2accb785",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=DataLoader(dataset=train_set,batch_size=64)\n",
    "testloader=DataLoader(dataset=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6547defc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5428"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,D_in,H_1,H_2,D_out):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H_1)\n",
    "        self.linear2=nn.Linear(H_1,H_2)\n",
    "        self.linear3=nn.Linear(H_2,D_out)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.linear1(x))  \n",
    "        x=torch.sigmoid(self.linear2(x))  \n",
    "        x=self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "input_dim=len(features)     # how many Variables are in the dataset\n",
    "hidden_dim_1 = 2000 # hidden layers\n",
    "hidden_dim_2 = 1000 # hidden layers\n",
    "output_dim=len(genie[\"targets\"])    # number of classes\n",
    "input_dim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a6d47c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model=Net(input_dim,hidden_dim_1,hidden_dim_2,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "955e38f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: torch.Size([2000, 5428])\n",
      "b torch.Size([2000])\n",
      "W: torch.Size([1000, 2000])\n",
      "b torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('W:',list(model.parameters())[0].size())\n",
    "print('b',list(model.parameters())[1].size())\n",
    "\n",
    "print('W:',list(model.parameters())[2].size())\n",
    "print('b',list(model.parameters())[3].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "328d684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate=0.1\n",
    "# criterion=nn.CrossEntropyLoss()\n",
    "# optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# https://discuss.pytorch.org/t/multi-label-classification-in-pytorch/905/15\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "735143fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea911464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9850e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/schmiddey/multiclass-classification-with-pytorch\n",
    "n_epochs=1000#1000\n",
    "loss_list=[]\n",
    "\n",
    "#n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "      \n",
    "\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z=model(x)\n",
    "        # calculate loss, da Cross Entropy benutzt wird muss ich in den loss Klassen vorhersagen, \n",
    "        # also Wahrscheinlichkeit pro Klasse. Das mach torch.max(y,1)[1])\n",
    "        loss=criterion(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.data)\n",
    "        \n",
    "        \n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2217cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fded3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=torch.max(z.data,1)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c942cbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 8\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, y_test)\n\u001b[0;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack4nf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack4nf\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Linear(len(features), len(genie[\"targets\"])) # predict logits for 5 classes\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_test)\n",
    "    loss = criterion(output, y_test)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Loss: {:.3f}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076d5e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0210c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cfc46f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.795\n",
      "Loss: 0.687\n",
      "Loss: 0.597\n",
      "Loss: 0.521\n",
      "Loss: 0.459\n",
      "Loss: 0.407\n",
      "Loss: 0.364\n",
      "Loss: 0.328\n",
      "Loss: 0.297\n",
      "Loss: 0.272\n",
      "Loss: 0.250\n",
      "Loss: 0.231\n",
      "Loss: 0.214\n",
      "Loss: 0.200\n",
      "Loss: 0.187\n",
      "Loss: 0.176\n",
      "Loss: 0.166\n",
      "Loss: 0.157\n",
      "Loss: 0.148\n",
      "Loss: 0.141\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Linear(20, 5) # predict logits for 5 classes\n",
    "x = torch.randn(1, 20)\n",
    "y = torch.tensor([[1., 0., 1., 0., 0.]]) # get classA and classC as active\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Loss: {:.3f}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3290b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d02664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146565"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd544230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PRIMARY_RACE</th>\n",
       "      <th>SECONDARY_RACE</th>\n",
       "      <th>TERTIARY_RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>BIRTH_YEAR</th>\n",
       "      <th>CENTER</th>\n",
       "      <th>INT_CONTACT</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNRF3_DNP</th>\n",
       "      <th>ZNRF3_INS</th>\n",
       "      <th>ZNRF3_ONP</th>\n",
       "      <th>ZNRF3_SNP</th>\n",
       "      <th>ZRSR2_DEL</th>\n",
       "      <th>ZRSR2_DNP</th>\n",
       "      <th>ZRSR2_INS</th>\n",
       "      <th>ZRSR2_SNP</th>\n",
       "      <th>ZSWIM4_DEL</th>\n",
       "      <th>ZSWIM4_SNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GENIE-VICC-101416</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Non-Spanish/non-Hispanic</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>VICC</td>\n",
       "      <td>19225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GENIE-VICC-102225</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Non-Spanish/non-Hispanic</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>VICC</td>\n",
       "      <td>12057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GENIE-VICC-102424</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Non-Spanish/non-Hispanic</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>VICC</td>\n",
       "      <td>23505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GENIE-VICC-102966</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Non-Spanish/non-Hispanic</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>VICC</td>\n",
       "      <td>23426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GENIE-VICC-103244</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Not collected</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>VICC</td>\n",
       "      <td>18267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         PATIENT_ID     SEX PRIMARY_RACE SECONDARY_RACE  \\\n",
       "0           0  GENIE-VICC-101416  Female        White  Not collected   \n",
       "1           1  GENIE-VICC-102225  Female        White  Not collected   \n",
       "2           2  GENIE-VICC-102424  Female        White  Not collected   \n",
       "3           3  GENIE-VICC-102966    Male        White  Not collected   \n",
       "4           4  GENIE-VICC-103244  Female      Unknown  Not collected   \n",
       "\n",
       "   TERTIARY_RACE                 ETHNICITY  BIRTH_YEAR CENTER INT_CONTACT  \\\n",
       "0  Not collected  Non-Spanish/non-Hispanic      1961.0   VICC       19225   \n",
       "1  Not collected  Non-Spanish/non-Hispanic      1982.0   VICC       12057   \n",
       "2  Not collected  Non-Spanish/non-Hispanic      1952.0   VICC       23505   \n",
       "3  Not collected  Non-Spanish/non-Hispanic      1951.0   VICC       23426   \n",
       "4  Not collected                   Unknown      1964.0   VICC       18267   \n",
       "\n",
       "   ... ZNRF3_DNP  ZNRF3_INS ZNRF3_ONP  ZNRF3_SNP  ZRSR2_DEL  ZRSR2_DNP  \\\n",
       "0  ...       0.0        0.0       0.0        0.0        0.0        0.0   \n",
       "1  ...       0.0        0.0       0.0        0.0        0.0        0.0   \n",
       "2  ...       0.0        0.0       0.0        0.0        0.0        0.0   \n",
       "3  ...       0.0        0.0       0.0        0.0        0.0        0.0   \n",
       "4  ...       0.0        0.0       0.0        0.0        0.0        0.0   \n",
       "\n",
       "   ZRSR2_INS  ZRSR2_SNP  ZSWIM4_DEL  ZSWIM4_SNP  \n",
       "0        0.0        0.0         0.0         0.0  \n",
       "1        0.0        0.0         0.0         0.0  \n",
       "2        0.0        0.0         0.0         0.0  \n",
       "3        0.0        0.0         0.0         0.0  \n",
       "4        0.0        0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 5455 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f65bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f81d7779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NF1_DEL    15272\n",
       "NF1_DNP    15272\n",
       "NF1_INS    15272\n",
       "NF1_ONP    15272\n",
       "NF1_SNP    15272\n",
       "NF2_DEL    15272\n",
       "NF2_DNP    15272\n",
       "NF2_INS    15272\n",
       "NF2_ONP    15272\n",
       "NF2_SNP    15272\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[genie[\"targets\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "820674e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PRIMARY_RACE</th>\n",
       "      <th>SECONDARY_RACE</th>\n",
       "      <th>TERTIARY_RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>BIRTH_YEAR</th>\n",
       "      <th>CENTER</th>\n",
       "      <th>INT_CONTACT</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNRF3_DNP</th>\n",
       "      <th>ZNRF3_INS</th>\n",
       "      <th>ZNRF3_ONP</th>\n",
       "      <th>ZNRF3_SNP</th>\n",
       "      <th>ZRSR2_DEL</th>\n",
       "      <th>ZRSR2_DNP</th>\n",
       "      <th>ZRSR2_INS</th>\n",
       "      <th>ZRSR2_SNP</th>\n",
       "      <th>ZSWIM4_DEL</th>\n",
       "      <th>ZSWIM4_SNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 PATIENT_ID  SEX PRIMARY_RACE SECONDARY_RACE TERTIARY_RACE  \\\n",
       "0         NaN        NaN  NaN          NaN            NaN           NaN   \n",
       "1         NaN        NaN  NaN          NaN            NaN           NaN   \n",
       "2         NaN        NaN  NaN          NaN            NaN           NaN   \n",
       "3         NaN        NaN  NaN          NaN            NaN           NaN   \n",
       "4         NaN        NaN  NaN          NaN            NaN           NaN   \n",
       "\n",
       "  ETHNICITY  BIRTH_YEAR CENTER INT_CONTACT  ... ZNRF3_DNP  ZNRF3_INS  \\\n",
       "0       NaN         NaN    NaN         NaN  ...       NaN        NaN   \n",
       "1       NaN         NaN    NaN         NaN  ...       NaN        NaN   \n",
       "2       NaN         NaN    NaN         NaN  ...       NaN        NaN   \n",
       "3       NaN         NaN    NaN         NaN  ...       NaN        NaN   \n",
       "4       NaN         NaN    NaN         NaN  ...       NaN        NaN   \n",
       "\n",
       "  ZNRF3_ONP  ZNRF3_SNP  ZRSR2_DEL  ZRSR2_DNP  ZRSR2_INS  ZRSR2_SNP  \\\n",
       "0       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   ZSWIM4_DEL  ZSWIM4_SNP  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "\n",
       "[5 rows x 5455 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset[genie[\"targets\"]].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e3df2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0b6cf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131293"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9e59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67473669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9efc7380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5438"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mutation_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82cce945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5428"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "910a9447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79fd46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65922e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38aabeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "num_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5327113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(tree_method=\"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b658e7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26259, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8402dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40a54e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=16, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=16, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=16, random_state=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=16, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "predictions.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6313a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/the-innovation/multi-label-classification-example-with-multioutputclassifier-and-xgboost-in-python-98c84c7d379f\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "331224e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classify',\n",
      "                 MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
      "                                                               booster=None,\n",
      "                                                               colsample_bylevel=None,\n",
      "                                                               colsample_bynode=None,\n",
      "                                                               colsample_bytree=None,\n",
      "                                                               enable_categorical=False,\n",
      "                                                               gamma=None,\n",
      "                                                               gpu_id=None,\n",
      "                                                               importance_type=None,\n",
      "                                                               interaction_constraints=None,\n",
      "                                                               learning_rate=None,\n",
      "                                                               max_delta_step=None,\n",
      "                                                               max_depth=None,\n",
      "                                                               min_child_weight=None,\n",
      "                                                               missing=nan,\n",
      "                                                               monotone_constraints=None,\n",
      "                                                               n_estimators=100,\n",
      "                                                               n_jobs=None,\n",
      "                                                               num_parallel_tree=None,\n",
      "                                                               predictor=None,\n",
      "                                                               random_state=None,\n",
      "                                                               reg_alpha=None,\n",
      "                                                               reg_lambda=None,\n",
      "                                                               scale_pos_weight=None,\n",
      "                                                               subsample=None,\n",
      "                                                               tree_method=None,\n",
      "                                                               validate_parameters=None,\n",
      "                                                               verbosity=None)))])\n"
     ]
    }
   ],
   "source": [
    "classifier = MultiOutputClassifier(XGBClassifier())\n",
    "\n",
    "clf = Pipeline([('classify', classifier)])\n",
    "\n",
    "print (clf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80d6e796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:15:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:19:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:23:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:51] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:30:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:34:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:37:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:41:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:44:52] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:47:51] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9235690620358734\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b035310",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0d55e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC y1: 0.4999, y2: 0.5000, y3: 0.5043, y4: 0.5000, y5: 0.5736\n"
     ]
    }
   ],
   "source": [
    "auc_y1 = roc_auc_score(y_test[:,0],yhat[:,0])\n",
    "auc_y2 = roc_auc_score(y_test[:,1],yhat[:,1])\n",
    "auc_y3 = roc_auc_score(y_test[:,2],yhat[:,2])\n",
    "auc_y4 = roc_auc_score(y_test[:,3],yhat[:,3])\n",
    "auc_y5 = roc_auc_score(y_test[:,4],yhat[:,4])\n",
    "\n",
    "print(\"ROC AUC y1: %.4f, y2: %.4f, y3: %.4f, y4: %.4f, y5: %.4f\" % (auc_y1, auc_y2, auc_y3, auc_y4, auc_y5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84aefd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25888     7]\n",
      " [  364     0]]\n"
     ]
    }
   ],
   "source": [
    "cm_y1 = confusion_matrix(y_test[:,0],yhat[:,0])\n",
    "cm_y2 = confusion_matrix(y_test[:,1],yhat[:,1])\n",
    "cm_y3 = confusion_matrix(y_test[:,2],yhat[:,2])\n",
    "cm_y4 = confusion_matrix(y_test[:,3],yhat[:,3])\n",
    "cm_y5 = confusion_matrix(y_test[:,4],yhat[:,4])\n",
    "\n",
    "print (cm_y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aee922d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     25895\n",
      "           1       0.00      0.00      0.00       364\n",
      "\n",
      "    accuracy                           0.99     26259\n",
      "   macro avg       0.49      0.50      0.50     26259\n",
      "weighted avg       0.97      0.99      0.98     26259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "cr_y1 = classification_report(y_test[:,0],yhat[:,0])\n",
    "cr_y2 = classification_report(y_test[:,1],yhat[:,1])\n",
    "cr_y3 = classification_report(y_test[:,2],yhat[:,2])\n",
    "cr_y4 = classification_report(y_test[:,3],yhat[:,3])\n",
    "cr_y5 = classification_report(y_test[:,4],yhat[:,4])\n",
    "\n",
    "print (cr_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaccd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d401f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(X_train, y_train,\n",
    "#         eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "#         eval_metric='mlogloss',\n",
    "#         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1618d977",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (32, 5) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_multilabel_classification(\n\u001b[0;32m      5\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m clf \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m np\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_allclose(clf\u001b[38;5;241m.\u001b[39mpredict(X), y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack4nf\\lib\\site-packages\\xgboost\\core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    505\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack4nf\\lib\\site-packages\\xgboost\\sklearn.py:1225\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe option use_label_encoder=True is incompatible with inputs \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m   1221\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mof type cuDF or cuPy. Please set use_label_encoder=False when \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m   1222\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstructing XGBClassifier object. NOTE: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m   1223\u001b[0m                          label_encoder_deprecation_msg)\n\u001b[0;32m   1224\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(label_encoder_deprecation_msg, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[1;32m-> 1225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le \u001b[38;5;241m=\u001b[39m \u001b[43mXGBoostLabelEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1226\u001b[0m     label_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack4nf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98\u001b[0m, in \u001b[0;36mLabelEncoder.fit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit label encoder.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m        Fitted label encoder.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m _unique(y)\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hack4nf\\lib\\site-packages\\sklearn\\utils\\validation.py:1156\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m   1147\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1148\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1153\u001b[0m         )\n\u001b[0;32m   1154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[1;32m-> 1156\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1158\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (32, 5) instead."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_multilabel_classification(\n",
    "    n_samples=32, n_classes=5, n_labels=3, random_state=0\n",
    ")\n",
    "clf = xgb.XGBClassifier(tree_method=\"hist\")\n",
    "clf.fit(X, y)\n",
    "np.testing.assert_allclose(clf.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43c6974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42427a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b39508",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m create_folder(model_path)\n\u001b[0;32m      3\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "# model_path = f\"model_{target}\"\n",
    "# create_folder(model_path)\n",
    "ds = ds.fillna(0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ds[features], ds[target],\n",
    "                                                    test_size=0.20, random_state=42)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "params_k = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'subsample': 0.8,\n",
    "    'subsample_freq': 1,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'max_bin': 300,\n",
    "    'n_estimators': 2000,\n",
    "    'boost_from_average': False,\n",
    "    \"random_seed\": 42}\n",
    "\n",
    "model_gbm = lgb.train(params_k, train_data, valid_sets=[test_data],\n",
    "                      num_boost_round=5000, early_stopping_rounds=25,\n",
    "                      verbose_eval=50)\n",
    "joblib.dump(model_gbm, f'{model_path}/model_lgb.pkl')\n",
    "\n",
    "# evaluate_model(model_gbm, X_test, y_test, model_path)\n",
    "\n",
    "# model_interpretability(model_gbm, X_test, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07814ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
